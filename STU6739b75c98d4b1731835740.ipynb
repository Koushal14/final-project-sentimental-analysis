{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMlSDOZ176VP",
        "outputId": "be2b66ff-bcd9-47e1-c5f9-455e24079ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model: 76.50%\n",
            "Results saved as Results.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "file_path = \"/content/Restaurant_Reviews 1.tsv\"  # Adjust path as needed\n",
        "data = pd.read_csv(file_path, delimiter='\\t', quoting=3)\n",
        "\n",
        "# Adding a column + stopwords\n",
        "data['Stopwords'] = data['Review'].apply(\n",
        "    lambda x: ' '.join([word for word in x.split() if word in stopwords.words('english')])\n",
        ")\n",
        "\n",
        "# Cleaning the data\n",
        "data['Cleaned Data'] = data['Review'].str.lower()  # Lowercase all text\n",
        "data['Cleaned Data'] = data['Cleaned Data'].str.replace('[^a-zA-Z]', ' ', regex=True)  # Remove non-alphabetic characters\n",
        "data['Cleaned Data'] = data['Cleaned Data'].apply(\n",
        "    lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')])\n",
        ")\n",
        "data['Cleaned Data'] = data['Cleaned Data'].apply(\n",
        "    lambda x: ' '.join([Word(word).lemmatize() for word in x.split()])\n",
        ")\n",
        "\n",
        "# Vectorizing\n",
        "vectorizer = CountVectorizer(max_features=2000)\n",
        "X = vectorizer.fit_transform(data['Cleaned Data']).toarray()\n",
        "Y = data['Liked']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Adding a column for analysis\n",
        "data['Analysis'] = data['Liked'].apply(lambda x: 'Positive' if x == 1 else 'Negative')\n",
        "\n",
        "# Saving to Excel\n",
        "output_file = \"Results.xlsx\"  # Output file name\n",
        "data.to_excel(output_file, index=False)\n",
        "\n",
        "# Printing accuracy and confirmation\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "print(f\"Accuracy of model: {accuracy * 100:.2f}%\")\n",
        "print(f\"Results saved as {output_file}\")\n"
      ]
    }
  ]
}